---
layout: post
title:  "시간 복잡도를 뛰어넘는 상수 줄이기"
date:   2019-10-17-21:55
author: djm03178
tags: 상수, 시간 복잡도, constant, time complexity
---

## 개요 ##
알고리즘을 공부하면 언제나 등장하고, 항상 신경써야 하는 요소가 있습니다. 바로 **시간 복잡도** 입니다. 공간 복잡도도 중요한 요소이기는 하지만, 메모리 사용량만큼의 시간이 걸리는 알고리즘은 효율적이지 않은 경우가 많기 때문에 상대적으로 덜 언급되곤 합니다.

하지만 어느 분야나 그렇듯이 이론과 현실에는 거리가 있기 마련입니다. 정확히는 알고리즘을 공부할 때 배우는 요소들은 문제를 푸는 수학적인 방법만을 고려한 것이지만, 문제 풀이를 할 때는 그 알고리즘을 프로그래밍 언어로 구현해내야 하고, 실제로 컴퓨터를 통해 실행시켜야 하기 때문에 시간 복잡도를 계산해서 예측한 속도와는 큰 차이를 보이는 경우가 많습니다. 어떻게 보면 문제를 풀기 위해 코드를 작성하고 실행하는 과정 전체에서 알고리즘 이론에 해당하는 부분은 굉장히 작은 것일 수도 있습니다.

당장 그 프로그래밍 언어가 CPU가 인식할 수 있는 기계어로 직접 번역되는지, 가상 머신이 빠르게 실행할 수 있는 바이트 코드로 변환되는지, 또는 코드 자체를 실행할 때마다 읽는지에 따라서만도 수십, 수백 배의 속도 차이가 발생할 수 있고, 같은 언어라도 컴파일러가 얼마나 최적화를 잘 해주는지에 따라 무시할 수 없는 차이를 보이기도 합니다. 그 뿐만 아니라 실행 시점에서의 시스템 상태에 따라서도 시간 차이가 발생하는 등 예측이 불가능한 요소들도 분명히 존재합니다.

정확히 어떤 코드가 어느 정도의 시간을 걸리게 할 것인가를 판단하기 위해서는 컴파일러, 컴퓨터 구조, 운영체제 등의 다양한 분야에 대한 깊은 이해가 필요하기 때문에 사실상 불가능에 가깝습니다. 그래서 이 글에서는 코드의 실행 과정을 하나부터 열까지 파헤치기보다는, 실험을 통해 대략적인 상수를 비교하고 그에 큰 영향을 미쳤을 요소가 무엇일지 분석하는 방향으로 서술하려고 합니다.

## 상수(constant)란? ##
우선 이 글이 무엇에 대해 이야기하려는 것인지를 명확히 하기 위해, 상수가 무엇인지에 대해 먼저 설명하겠습니다.

일반적으로 어떤 알고리즘의 수행 시간이 점근적으로 $N$의 제곱에 비례한다고 할 때, 이를 점근 표기법으로 다음과 같이 표기합니다.

$$O(N^2)$$

하지만 이 수식 자체만으로 우리가 유추할 수 있는 건, $N$이 무한히 커져감에 따라 수행 시간이 $N^2$에 비례해서 커진다는 것 정도이지, 현실적인 범위의 $N$에 대해 모든 $O(N^3)$의 알고리즘들보다 항상 빠르다는 걸 보장하는 것은 아닙니다.

예를 들어, 다음의 세 수식은 모두 수학적으로 같은 복잡도를 나타냅니다.

$$O(N^2)$$ $$O(2N^2+10000)$$ $$O(\dfrac{N^2}{10000})$$

결국 이론적으로는 이 $N^2$에 $2$가 곱해지든, $\dfrac{1}{10000}$이 곱해지든, $10000$이 더해지든 시간 복잡도에 전혀 영향을 주지 못한다는 이야기가 됩니다. 다만 편의상으로 "이와 같은 알고리즘을 수행할 때는 $N^2$ 번의 연산을 두 번 수행한다" 와 같은 느낌으로 $O(2N^2)$과 같이 상수배를 붙여서 써주고는 합니다.

실제 예시를 들자면, 모든 원소의 값이 서로 다른 배열을 삽입 정렬할 때의 평균 시간 복잡도는 $O(N^2)$이지만, 실제로 원소를 비교하는 횟수를 세어보면 대략 $\dfrac{1}{4}N^2$번 정도임을 알 수 있습니다. 이는 단순하게 구현한 버블 정렬이 항상 $\dfrac{1}{2}N^2$번 정도의 비교를 요구하는 것과는 대조됩니다. 그렇지만 우리는 이것을 시간 복잡도에 반영하지 않고, 둘 다 같은 $O(N^2)$ 알고리즘이라고만 배울 뿐입니다.

그런데 이전의 [특별한 정렬 알고리즘들](http://www.secmem.org/blog/2019/04/10/special-sorts/) 글에서 다루었듯이, 삽입 정렬은 실제로 $N$이 작을 때에는 매우 빠르게 동작하기 때문에 분할 정복 기법을 사용하는 정렬 알고리즘들은 대체로 범위가 작아질 경우 삽입 정렬을 사용해서 퍼포먼스를 높이곤 합니다. 이론에서 다루는 시간 복잡도를 넘어서, 실제로 빠르게 동작하는 것, 즉, **상수** 가 작다는 것을 이용한 것입니다.

상수에는 이렇게 눈에 띄는 연산의 *횟수* 가 줄어드는 경우도 있지만, 그저 실행하는 코드 자체가 다르기 때문에 큰 차이가 발생하기도 합니다. 문제 풀이에서 알아두면 좋은 상수 줄이기 테크닉에는 어떤 것들이 있는지를 지금부터 알아보도록 하겠습니다.

## 실험 환경 ##
먼저 여러 코드들의 성능을 실험하기 위한 실험 환경은 다음과 같습니다.
* Intel Core i5-8250U CPU 1.60GHz
* Ubuntu 18.04.1 LTS
* g++ 7.4.0
  * -std=c++17
  * -O2

## 입출력 ##
입출력은 아마도 가장 유명하면서도 많은 사람들의 골치를 아프게 한 무거운 연산일 것입니다. 백준 온라인 저지를 이용하는 사람들이라면 채점 환경에 특화된 실험 결과([입력](https://www.acmicpc.net/blog/view/56), [출력](https://www.acmicpc.net/blog/view/57))를 보면 좋습니다.

이 글의 실험 환경도 비슷하니 따로 측정을 하지는 않겠지만, 왜 저런 차이가 발생하는지에 대한 분석을 해봅시다.

### ios_base::sync_with_stdio(false) ###
이 문장은 이제는 너무나 유명해서 C++의 `cin`, `cout`으로 문제 풀이를 하는 사람이라면 거의 필수로 사용하고 있습니다. 그러나 이 문장이 왜 입출력 속도를 향상시키는지는 잘 알아보지 않으신 분이 많습니다.

C++은 C에 기반하여 만들어진 언어이고 C의 라이브러리들 또한 거의 그대로 사용할 수 있게 제공해 줍니다. 이 중에서는 표준 입출력 스트림(`stdio`)이 포함되는데, C++은 기본적으로 C의 입출력 스트림과 C++의 입출력 스트림(`iostream`)을 혼용해서 사용하더라도 문제가 없도록 `iostream`과 `stdio`를 동기화(synchronize)해두고 시작합니다. 그 때문에 `iostream`의 입출력 스트림을 사용할 때마다, `stdio`의 버퍼로부터 내용을 읽거나 stdio의 버퍼에 내용을 쓰며 동기화를 유지해주게 됩니다. 하지만 이 문장이 호출되면, 인자로 전달되는 `false`가 나타내듯이 둘 사이의 동기화를 해제하게 됩니다. 그러면 `iostream`은 자신만의 입출력 버퍼를 가질 수 있게 되어, `stdio`의 눈치를 보지 않고 입출력을 수행할 수 있게 되기 때문에 빨라지는 것입니다.
.
.
.
.
.
