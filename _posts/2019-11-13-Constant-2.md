---
layout: post
title:  "더 빠른 문제 풀이 코드를 위한 상수 줄이기 2"
date:   2019-11-13-19:41
author: djm03178
tags: 상수, 시간 복잡도, constant, time complexity
---

## 개요 ##
[지난 글](http://www.secmem.org/blog/2019/10/17/Constant/)에서는 문제 풀이에 있어 상수가 가지는 의미와, 상수 차이에 의해 현저히 드러나는 퍼포먼스의 차이를 몇 가지 실험을 통해 보았습니다. 먼저 입출력 방법에 따라 수십 배 이상도 차이가 벌어질 수 있음을 보았고, `std::set`과 같이 Red–black tree를 쓰는 자료구조는 `std::priority_queue`에 비해 같은 연산을 하더라도 훨씬 느리다는 것을 보았습니다. 또한 광범위한 영역의 메모리를 빠르게 특정 값으로 채우거나, 복사하거나, 옮기는 데에는 1바이트씩 반복문을 통해 수행하는 것보다 `memset`, `memcpy`, `memmove` 등의 함수를 사용하는 것이 월등히 빠르다는 것도 살펴보았습니다.

이번 글에서는 지난 글에 이어 문제 풀이 상황에서 자주 마주하게 되는, 유용한 상수 줄이기 테크닉을 여러 가지 추가로 소개하고자 합니다.

## 캐시 히트 ##
컴퓨터의 메모리는 메인 메모리 하나로만 이루어져 있지 않습니다. CPU의 성능이 점점 향상되는 것에 비해 주 메모리로부터 데이터를 읽어오고 쓰는 것은 여전히 컴퓨터의 성능의 병목이라고 할 수 있기 때문에, 그 속도를 향상시키기 위한 노력이 하드웨어에 많이 들어가 있습니다. 그 중 하나가 [캐시(cache)](https://en.wikipedia.org/wiki/CPU_cache)입니다.

이 글에서 필요한 부분만 간략하게 설명하자면, 데이터를 주 메모리에서 읽기 위해 매번 I/O를 발생시키는 것은 지나치게 많은 시간을 소요하기 때문에, 일반적으로 하드웨어에는 여러 단계의 캐시들을 두어 자주 사용하는 주소의 메모리를 캐시에 매핑시켜두고 찾고자 하는 주소가 캐시에 존재하는 경우 메인 메모리보다 훨씬 빠르게 접근하여 시간을 줄이고 있습니다. 문제는 여기서 '자주 사용한다는 것'을 어떻게 측정하는가인데, 이에 대해 대표적으로 사용되는 지표가 바로 공간 집약성과 시간 집약성입니다. 공간 집약성은 최근에 사용한 주소와 가까이 있는 주소를 사용할 가능성이 높다는 것이고, 시간 집약성은 최근에 사용한 주소는 금방 다시 사용할 가능성이 높다는 것입니다.

캐시와 메인 메모리 사이에 데이터가 오고 가는 것 역시 많은 시간을 소요하기에, 캐시에는 한 번에 일정량의 주소를 한 번에 매핑해두고 다른 주소에 의해 교체될 때까지 사용하게 됩니다. 접근하고자 하는 주소가 캐시에 매핑되어있는 경우를 캐시 히트(cache hit)라고 하며, 캐시에 존재하지 않아 메인 메모리로부터 데이터를 가지고 와야 하는 경우를 캐시 미스(cache miss)라고 합니다. 이 부분에서 다루고자 하는 것은 바로 이 캐시 히트의 비율을 높이는 것입니다.

위에서 언급한 공간 집약성과 시간 집약성을 높이기 위해서는 기본적으로 코드가 다음과 같은 특징을 가져야 합니다.

> 좁은 범위의 메모리에서 오래 작업한다.

이를 지키는 것과 지키지 않는 것의 차이를 보기 위해 간단한 실험을 해보겠습니다. 실험 환경은 지난 글과 같습니다.

```cpp
#include <bits/stdc++.h>
using namespace std;
​
int main()
{
	ios_base::sync_with_stdio(false);
	cin.tie(0);
​
	int n, m;
	cin >> n >> m;
​
	int *arr = new int[n];
	int *perm = new int[n];
​
	for (int i = 0; i < n; i++)
	{
		arr[i] = 1;
		perm[i] = i;
	}
​
	random_shuffle(perm, perm + n);

	clock_t st = clock();
​
	long long sum = 0;
	for (int i = 0; i < m; i++)
	{
		for (int j = 0; j < n; j++)
			sum += arr[perm[j]];
	}
​
	clock_t ed = clock();
​
	cout << sum << '\n';
	cout << fixed;
	cout.precision(3);
	cout << "Time: " << (ed - st) / double(CLOCKS_PER_SEC) << " seconds.\n";
}
```
**
위 코드는 단순히 크기가 `n`인 `int`형 배열 `arr`을 생성하고, `perm` 배열을 통해 인덱스의 순서를 무작위로 섞은 뒤 그 순서대로 `arr`의 원소들에 접근하는 것을 `m`번 반복합니다. 이 코드에서 `random_shuffle`을 실행하지 않으면 `arr`의 원소들도 순차적으로 접근하게 됩니다. 두 코드의 실행 결과를 `n`과 `m`에 변화를 주면서 실험한 결과는 다음과 같습니다.

* `n=100000, m=100000`: 9.315s / 6.080s (약 1.53배)
* `n=1000000, m=10000`: 37.175s / 6.315s (약 5.89배)
* `n=10000000, m=1000`: 242.114s / 6.373s (**약 37.99배**)

루프를 도는 총 횟수에는 거의 차이가 없기 때문에, 공간 집약성이 좋은 코드는 수행 시간 역시 크게 변화가 없는 것을 볼 수 있습니다. 반면에 공간 집약성이 나쁜 코드는 원소의 개수인 `n`이 커질 때마다 수행 시간이 폭발적으로 증가하는 것을 볼 수 있습니다. 배열의 크기가 커질수록 접근하는 인덱스마다 캐시 미스가 날 확률이 매우 커지기 때문입니다.

이 차이를 결코 무시할 수 없다는 것은 확실해 보입니다. 그렇다면 이를 문제 풀이에서 어떻게 활용할 수 있을까요? 가장 자주 만나면서도 쉽게 실천할 수 있는 곳이 바로 다차원 배열입니다. 다차원 배열에서 가장 낮은 차원은 주소가 연속되어 할당되는 반면, 높은 차원은 인덱스 1당 낮은 차원의 크기만큼의 주소 차이가 있기 때문에 캐시에 매핑된 영역을 금방 넘어서게 됩니다. 그래서 다차원 배열을 순회할 때는 항상 높은 차원의 인덱스들은 고정된 채로 가장 낮은 차원을 연속적으로 모두 본 뒤, 그 다음 차원의 다음 인덱스를 보는 것이 이득입니다.

또한 동적으로 주소를 할당받아 사용하는 링크드 리스트 역시 그다지 집약성이 좋지 않은 자료구조로, 리스트의 길이가 길어질수록 그 효율성이 매우 떨어집니다. 실제로 링크드 리스트를 사용하는 `std::list`는 `std::vector`나 `std::deque`와 같이 연속된 공간에 원소를 저장하는 자료구조에 비해 대부분의 연산에 대한 퍼포먼스가 크게 밀린다는 실험 결과도 있습니다.[^1]

때로는 주어지는 수의 범위가 배열 하나로 충분히 커버가 가능하더라도(예: 100만), 좌표압축을 통해 입력되는 수의 개수 내로 그 크기를 줄이는 것이 (예: 10만) 큰 시간 단축을 끌어낼 수도 있습니다.

![100만까지의 수를 10만까지로 압축했을 때의 차이는 이렇게 큽니다...](../assets/images/constant2/1.png)

## 실수형을 적게 사용하기 ##
일반적으로 문제 풀이에서 실수형을 사용하게 되는 일은 적지만, 간혹 스페셜 저지[^2]를 통해 오차를 허용하고 실수형의 답을 출력하게 하는 경우가 있습니다.[^3] 하지만 실수형을 사용하는 데에 조심해야 할 것은 오차 뿐만이 아닙니다. 실수형 연산이 정수형 연산에 비해 느리다는 것 또한 충분히 고려해야 할 사항입니다.

실수형이 얼마나 느린지 실험해보기 위해 다음과 같은 프로그램을 작성하고, 테스트해 봅시다.

```cpp
#include <bits/stdc++.h>
using namespace std;
​
typedef double T;
​
int main()
{
	ios_base::sync_with_stdio(false);
	cin.tie(0);
​
	int n;
	cin >> n;
​
	T *arr = new T[n];
	for (int i = 0; i < n; i++)
		arr[i] = rand() % (1 << 16);
​
	clock_t st = clock();
	T sum = 0;
	for (int i = 0; i < n; i++)
		sum += arr[i] * arr[i];
	clock_t ed = clock();
​
	cout << sum << '\n';
	cout.precision(3);
	cout << fixed;
	cout << "Time: "<< (ed - st) / double(CLOCKS_PER_SEC) << " seconds.\n";
}
```
**

비교할 코드는 위의 `typedef double T;`에서 `double`을 `long long`으로 바꾼 코드입니다. 실험 환경에서 둘의 크기가 같기 때문에 비교적 공정한 비교가 가능해서 나온 선택입니다.

위의 코드에서 각각 5억을 입력으로 넣은 결과는 다음과 같습니다.

* double: 0.605s
* long long: 0.283s

2배가 조금 넘는 차이라 크지 않아 보이기도 하지만, 루프가 돌 때마다 `i`가 증가되고 `n`과의 비교를 하는 연산, 그리고 `arr[i]`에 접근하는 시간이 모두 포함된 시간이라는 것을 감안해야 합니다. 순수하게 산술연산 시간만을 비교하게끔 만드는 것은 어렵지만, 2배보다는 훨씬 큰 차이가 발생할 것임을 충분히 짐작할 수 있습니다.

이와 같은 사실을 활용할 수 있는 상황으로는 대표적으로 두 정수 좌표 사이의 유클리드 거리를 저장해야 하는 경우, 굳이 `double`형을 사용하여 제곱하고 더한 뒤 루트를 씌우는 행동을 하는 것보다는 그냥 `long long`형에 제곱하여 더한 상태로만 저장해서 사용하는 것이 훨씬 효율적이라는 것 등이 있습니다. 실수 연산이 필요하지 않다면, 정수 연산으로만 해결이 가능하다면 가능하면 정수만을 사용하는 것이 정확도 면에서나, 속도 면에서나 우월하다는 것을 인지하고 문제를 푸는 것이 좋겠습니다.

## 정수 나눗셈을 적게 사용하기 ##
하지만 이와 같이 빠른 정수형에도 치명적인 약점이 있으니, 바로 나누기 연산은 빠르게 감당하지 못한다는 것입니다. 이는 CPU가 사칙연산 중 덧셈, 뺄셈, 곱셈은 병렬적인 회로 구성으로 빠르게 연산하는 것이 가능하지만 나눗셈은 마땅한 방법이 없어 여러 단계를 거쳐야 하기 때문입니다. 여기에서 말하는 나누기 연산은 나머지 연산 역시 포함합니다.

이번에는 아래와 같은 코드를 통해 이를 실험해 봅시다.

```cpp
#include <bits/stdc++.h>
using namespace std;
​
int main()
{
	ios_base::sync_with_stdio(false);
	cin.tie(0);
​
	int n;
	cin >> n;
​
	long long *arr = new long long[n];
	for (int i = 0; i < n; i++)
		arr[i] = (long long)rand() + 1;
​
	clock_t st = clock();
	long long sum = 0;
	for (int i = 0; i < n - 6; i++)
		sum += (((((arr[i] / arr[i + 1]) % arr[i + 2]) / arr[i + 3]) % arr[i + 4]) / arr[i + 5]) / arr[i + 6];
    //		sum += (((((arr[i] + arr[i + 1]) - arr[i + 2]) + arr[i + 3]) - arr[i + 4]) + arr[i + 5]) - arr[i + 6];
	clock_t ed = clock();
​
	cout << sum << '\n';
	cout.precision(3);
	cout << fixed;
	cout << "Time: "<< (ed - st) / double(CLOCKS_PER_SEC) << " seconds.\n";
}
```
**

`sum`에 더해가는 과정에서 나눗셈 / 나머지 연산자를 사용한 것과, 덧셈 / 뺄셈 연산자를 사용한 것, 그리고 곱셈 연산자만을 사용한 것을 비교해 보았습니다. 과연 얼마나 차이가 날까요? 입력으로 1억을 넣고 실험해 보았습니다.

* 나눗셈 / 나머지: 6.270s
* 덧셈 / 뺄셈: 0.112s
* 곱셈 (오버플로 방지를 위해 원소의 값은 1~10으로 설정): 0.180s

정말 믿을 수 없도록 큰 차이가 납니다! 앞으로는 정수 연산이라고 안심하지 말고, 나눗셈의 횟수 역시 줄일 수 있는 곳이라면 최대한 줄이는 것이 퍼포먼스 향상에 큰 도움이 된다는 것을 인지하는 것이 좋겠습니다.

## 비트 연산자를 통한 시간 복잡도 뛰어넘기 ##
이번에는 지금까지의 실험에서 한 단계 더 나아가, 상수를 줄일 뿐 아니라 아예 시간복잡도가 더 좋은 연산을 실용적인 범위 내에서[^4] 뛰어넘는 것을 하나 보이려 합니다. 바로 비트 연산자들을 사용하여 `std::set<int>`의 연산, 또는 그것이 수행하기 어려운 연산들을 수행하는 것입니다. 거의 같은 기능을 `std::bitset`도 해주지만, 내부 로직을 이해하기 위해 직접 구현하도록 해보겠습니다. 좀 더 다양한 비트 연산자들의 활용법은 [이 글](http://www.secmem.org/blog/2019/10/19/handy-function-about-bit/)에 제시되어 있습니다.

먼저 이를 구현하기 전에 다음과 같은 연산을 수행해야 하는 상황을 가정해 봅시다.

> 집합의 각 원소는 [1, 100000] 범위의 정수값을 가진다.
> * 특정 집합에 `x`를 추가하는 연산 (이미 존재하면 무시)
> * 특정 집합에서 `x`를 제거하는 연산 (존재하지 않으면 무시)
> * 특정 집합에서 `x`보다 큰 최소의 수를 찾는 쿼리
> * 특정 집합에서 `x`보다 작은 최대의 수를 찾는 쿼리

여기까지는 `std::set`으로도 충분히 효율적으로 수행할 수 있지만, 비트 연산자를 써도 그 이상의 속도를 낼 수 있습니다. 비트셋을 구현한 코드는 다음과 같습니다.

```cpp
#include <bits/stdc++.h>
using namespace std;
​
typedef unsigned long long ull;
​
const int sz = 100000 / sizeof(ull) + 1;
​
struct bset {
	ull x[sz];
	bset()
	{
		memset(x, 0, sizeof x);
	}
​
	bset operator|(const bset &o) const {
		bset a;
		for (int i = 0; i < sz; i++)
			a.x[i] = x[i] | o.x[i];
		return a;
	}
​
	bset &operator|=(const bset &o) {
		for (int i = 0; i < sz; i++)
			x[i] |= o.x[i];
		return *this;
	}
​
	inline void add(int val)
	{
		x[val >> 6] |= (1ull << (val & 63));
	}
​
	inline void del(int val)
	{
		x[val >> 6] &= ~(1ull << (val & 63));
	}
​
	int kth(int k)
	{
		int i, cnt = 0;
		for (i = 0; i < sz; i++)
		{
			int c = __builtin_popcountll(x[i]);
			if (cnt + c >= k)
			{
				ull y = x[i];
				int z = 0;
				for (int j = 0; j < 64; j++)
				{
					z += ((x[i] & (1ull << j)) != 0);
					if (cnt + z == k)
						return i * 64 + j;
				}
			}
			cnt += c;
		}
		return -1;
	}
​
	int lower(int z)
	{
		int i = (z >> 6), j = (z & 63);
		if (x[i])
		{
			for (int k = j - 1; k >= 0; k--)
				if (x[i] & (1ull << k))
					return (i << 6) | k;
		}
		while (i > 0)
			if (x[--i])
				for (j = 63;; j--)
					if (x[i] & (1ull << j))
						return (i << 6) | j;
		return -1;
	}
​
	int upper(int z)
	{
		int i = (z >> 6), j = (z & 63);
		if (x[i])
		{
			for (int k = j + 1; k <= 63; k++)
				if (x[i] & (1ull << k))
					return (i << 6) | k;
		}
		while (i < sz - 1)
			if (x[++i])
				for (j = 0;; j++)
					if (x[i] & (1ull << j))
						return (i << 6) | j;
		return -1;
	}
};
```
**

우선 단순 원소 추가/제거 연산부터 실험해 보겠습니다. 아래와 같은 테스트 코드를 사용하여 둘을 비교해 봤습니다.

```cpp
int main()
{
	ios::sync_with_stdio(false);
	cin.tie(0);
​
	int n;
	cin >> n;
	int *arr = new int[n];
	for (int i = 0; i < n; i++)
	{
		arr[i] = rand() % 100000 + 1;
		if (rand() % 2)
			arr[i] = -arr[i];
	}
​
	clock_t st = clock();
	bset s;
	for (int i = 0; i < n; i++)
	{
		if (arr[i] > 0)
			s.add(arr[i]);
		else
			s.del(arr[i]);
	}
	clock_t ed = clock();
​
	cout.precision(3);
	cout << fixed;
	cout << "Time: " << (ed - st) / double(CLOCKS_PER_SEC) << " seconds.\n";
}
```
**

`std::set`을 사용한 테스트 코드는 다음과 같습니다.

```cpp

	clock_t st = clock();
	set<int> s;
	for (int i = 0; i < n; i++)
	{
		if (arr[i] > 0)
			s.insert(arr[i]);
		else
			s.erase(arr[i]);
	}
	clock_t ed = clock();
```

둘에 각각 1억의 입력을 주고 테스트한 결과는 다음과 같습니다.

* `bset`: 0.142s
* `std::set`: 11.159s

여기까지는 오히려 `std::set`의 연산이 시간 복잡도가 더 나쁘니까 어찌 보면 당연한 결과이지만, 그럼에도 불구하고 시간 차이가 거의 80배에 육박한다는 것만으로도 주목할 만합니다. 사실 이건 비트 연산자가 아닌 그냥 배열의 원소 한 칸을 통째로 사용해도 마찬가지이고, `std::set`이 느린 것이 큰 원인일 뿐입니다.

[^1]: https://baptiste-wicht.com/posts/2012/12/cpp-benchmark-vector-list-deque.html
[^2]: 답이 하나로 고정되지 않는 문제에서, 그 답이 올바른 답에 속하는지를 평가해 주는 프로그램을 말합니다.
[^3]: 특수한 이유로 오차를 허용하지 않고도 실수형을 사용해야만 하는 경우들도 있지만, 이 글에서는 논외로 합니다.
[^4]: 물론 시간 복잡도가 의미하는 것을 생각한다면 입력이 무한히 커질 수 있을 경우 시간 복잡도가 더 좋은 자료구조를 뛰어넘는다는 것은 절대로 불가능하지만, 문제 풀이에서 자주 등장하는 범위 내라면 충분히 가능한 경우가 많이 있습니다.
